{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Analisi dei dati"
      ],
      "metadata": {
        "id": "a85LyW-X75qf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmp8EyEyStxn"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykY4n99itA3h",
        "outputId": "b05e0cf3-1ebe-4fc7-d819-9c6579732755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Il dataset è presente su Google Drive come file zip\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYtW1STQtifj"
      },
      "outputs": [],
      "source": [
        "# Estrazione del contenuto del dataset\n",
        "!unzip \"/content/drive/MyDrive/Alzheimer_s_Dataset.zip\" -d \"/content/Alzheimer_s_Dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcG_sOzFa0dj"
      },
      "outputs": [],
      "source": [
        "# Percorso del dataset decompresso\n",
        "data = 'Alzheimer_s_Dataset'\n",
        "data_dir_train = 'Alzheimer_s_Dataset/train'\n",
        "data_dir_test = 'Alzheimer_s_Dataset/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMHGVbPes-se"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def merge_categories(parent_dir):\n",
        "    # Unisci le categorie in 'Demented'\n",
        "    for category in ['MildDemented', 'ModerateDemented', 'VeryMildDemented']:\n",
        "        src_dir = os.path.join(parent_dir, category)\n",
        "        dest_dir = os.path.join(parent_dir, 'Demented')\n",
        "        if not os.path.exists(dest_dir):\n",
        "            os.makedirs(dest_dir)\n",
        "        for file_name in os.listdir(src_dir):\n",
        "            src_file_path = os.path.join(src_dir, file_name)\n",
        "            new_file_name = f\"{category}_{file_name}\"\n",
        "            dest_file_path = os.path.join(dest_dir, new_file_name)\n",
        "            shutil.move(src_file_path, dest_file_path)\n",
        "\n",
        "def remove_empty_folders(parent_dir):\n",
        "    # Rimuovi le cartelle vuote\n",
        "    for category in ['MildDemented', 'ModerateDemented', 'VeryMildDemented']:\n",
        "        dir_path = os.path.join(parent_dir, category)\n",
        "        if os.path.exists(dir_path) and len(os.listdir(dir_path)) == 0:\n",
        "            os.rmdir(dir_path)\n",
        "\n",
        "# Esegui le operazioni sulle cartelle di training e test\n",
        "for directory in [data_dir_train, data_dir_test]:\n",
        "    merge_categories(directory)\n",
        "    remove_empty_folders(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "XBvIkk6M8APS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGNog8jns-sf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import cv2\n",
        "\n",
        "# Funzione di augmentation che esegue flip casuali e rotazioni\n",
        "def augment_image(input_image_path, output_image_path):\n",
        "    image = cv2.imread(input_image_path)\n",
        "\n",
        "    # Flip casuale\n",
        "    flip_hor = random.choice([True, False])\n",
        "    if flip_hor:\n",
        "        image = cv2.flip(image, 1)  # Flip orizzontale\n",
        "\n",
        "    # Rotazione casuale\n",
        "    angle = random.randint(-10, 10)\n",
        "    rows, cols, _ = image.shape\n",
        "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
        "    image = cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "    # Salva l'immagine augmentata\n",
        "    cv2.imwrite(output_image_path, image)\n",
        "\n",
        "# Funzione per bilanciare le classi nel dataset di training\n",
        "def balance_classes(data_type_dir, class_name, target_count=3000):\n",
        "    class_dir = os.path.join(data_type_dir, class_name)\n",
        "    current_count = len(os.listdir(class_dir))\n",
        "    augmentations_needed = target_count - current_count\n",
        "\n",
        "    if augmentations_needed > 0:\n",
        "        for i in range(augmentations_needed):\n",
        "            random_image_name = random.choice(os.listdir(class_dir))\n",
        "            random_image_path = os.path.join(class_dir, random_image_name)\n",
        "            augmented_image_name = f\"aug_{i}_{random_image_name}\"\n",
        "            augmented_image_path = os.path.join(class_dir, augmented_image_name)\n",
        "            augment_image(random_image_path, augmented_image_path)\n",
        "    else:\n",
        "        print(f\"La classe {class_name} ha già {current_count} immagini, non sono necessarie ulteriori augmentations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2eVtrkMs-sf"
      },
      "outputs": [],
      "source": [
        "# Bilancia la classe 'Demented' nel dataset di training\n",
        "balance_classes(data_dir_train, 'Demented')\n",
        "\n",
        "# Bilancia la classe 'NonDemented' nel dataset di training (assumendo che esista già questa cartella)\n",
        "balance_classes(data_dir_train, 'NonDemented')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulizia della cache"
      ],
      "metadata": {
        "id": "6lMlC2KP8IPD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYI5Ta349l9j"
      },
      "outputs": [],
      "source": [
        "# Percorso della cartella .ipynb_checkpoints\n",
        "checkpoints_path = os.path.join(data_dir_train, '.ipynb_checkpoints')\n",
        "\n",
        "# Controlla se la cartella .ipynb_checkpoints esiste e, in tal caso, la elimina\n",
        "if os.path.exists(checkpoints_path):\n",
        "    shutil.rmtree(checkpoints_path)\n",
        "    print(f\"Cartella {checkpoints_path} rimossa.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trasformazioni"
      ],
      "metadata": {
        "id": "QPjp-aEj8OAK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXVPfqplb3CU"
      },
      "outputs": [],
      "source": [
        "# Trasformazioni standard per il set di addestramento\n",
        "standard_transforms = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),  # Ridimensionamento per AlexNet\n",
        "    transforms.Grayscale(num_output_channels=1),  # Conversione in scala di grigi\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])  # Normalizzazione per un singolo canale\n",
        "])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}