{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Caricamento del modello"
      ],
      "metadata": {
        "id": "C60kJ8ZdWzKL"
      },
      "id": "C60kJ8ZdWzKL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06368f6-ddb8-48ef-b352-52f60c58f4da",
      "metadata": {
        "id": "f06368f6-ddb8-48ef-b352-52f60c58f4da",
        "outputId": "d097aa56-f433-4529-d905-aaf8e103f78f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Caricamento delle informazioni salvate\n",
        "loaded_info = torch.load('model/modello_fia12.pth')\n",
        "\n",
        "# Caricamento di AlexNet senza i pesi preaddestrati\n",
        "alexnet = alexnet(weights=None)\n",
        "\n",
        "# Modifica del primo strato convoluzionale\n",
        "alexnet.features[0] = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
        "\n",
        "# Modifica dell'ultimo strato fully-connected per la classificazione binaria\n",
        "alexnet.classifier[6] = nn.Linear(4096, 1)\n",
        "\n",
        "# Aggiunta della funzione di attivazione sigmoide all'ultimo strato\n",
        "alexnet.classifier.add_module(\"7\", nn.Sigmoid())\n",
        "\n",
        "# Congelamento dei pesi dei primi strati\n",
        "for param in alexnet.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Caricamento stato modello\n",
        "alexnet.load_state_dict(loaded_info['model_state_dict'])\n",
        "\n",
        "# Ricreazione dello stato dell'ottimizzatore\n",
        "optimizer = optim.Adam(alexnet.parameters(), lr=0.001)\n",
        "optimizer.load_state_dict(loaded_info['optimizer_state_dict'])\n",
        "\n",
        "# Ricreazione del criterio di perdita\n",
        "criterion = nn.BCELoss()  # o qualsiasi altro criterio usato\n",
        "criterion.load_state_dict(loaded_info['criterion_state_dict'])\n",
        "\n",
        "# Recupero delle altre informazioni\n",
        "epoch = loaded_info['epoch']\n",
        "preprocessing_params = loaded_info['preprocessing']\n",
        "\n",
        "# Metti il modello in modalità di valutazione\n",
        "alexnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4ae1ed-b987-43e6-a03e-f626a72d02af",
      "metadata": {
        "id": "5a4ae1ed-b987-43e6-a03e-f626a72d02af"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Definisci le trasformazioni\n",
        "standard_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Ridimensionamento per AlexNet\n",
        "    transforms.Grayscale(num_output_channels=1),  # Conversione in scala di grigi\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])  # Normalizzazione per un singolo canale\n",
        "])\n",
        "\n",
        "# Crea un dizionario per mappare gli indici alle etichette\n",
        "class_labels = {0: \"Non demented\", 1: \"Demented\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valutazione"
      ],
      "metadata": {
        "id": "V8xh8hPTW4m0"
      },
      "id": "V8xh8hPTW4m0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f74f8a96-614c-4593-82eb-cc8e0c645335",
      "metadata": {
        "id": "f74f8a96-614c-4593-82eb-cc8e0c645335"
      },
      "outputs": [],
      "source": [
        "# Carica l'immagine singola e applica le trasformazioni\n",
        "img = Image.open(\"test/32 (50).jpg\")\n",
        "img_t = standard_transforms(img)\n",
        "batch_t = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "# Esegui la predizione\n",
        "with torch.no_grad():\n",
        "    output = alexnet(batch_t)\n",
        "\n",
        "# output è ora un tensore contenente le probabilità delle classi\n",
        "\n",
        "predicted_probability = output.item()\n",
        "print(predicted_probability)\n",
        "\n",
        "if predicted_probability > 0.5:\n",
        "    predicted_label = \"Non demented\"\n",
        "else:\n",
        "    predicted_label = \"Demented\"\n",
        "\n",
        "print(f\"La predizione del modello è: '{predicted_label}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87740b35-bf6f-4706-9151-9d469a9ba6dc",
      "metadata": {
        "id": "87740b35-bf6f-4706-9151-9d469a9ba6dc",
        "outputId": "3d6b135d-d681-4d70-f6e3-17869d6056c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero di immagini classificate come 'Demented': 229\n",
            "Numero di immagini classificate come 'Non demented': 411\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Percorso della cartella con le immagini di test\n",
        "test_folder = \"test\"\n",
        "\n",
        "# Contatori per le predizioni\n",
        "count_non_demented = 0\n",
        "count_demented = 0\n",
        "\n",
        "# Lista per salvare i risultati delle predizioni\n",
        "predictions = []\n",
        "\n",
        "# Itera su tutti i file nella cartella di test\n",
        "for img_file in os.listdir(test_folder):\n",
        "    img_path = os.path.join(test_folder, img_file)\n",
        "\n",
        "    # Assicurati che il file sia un'immagine\n",
        "    if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        # Carica l'immagine e applica le trasformazioni\n",
        "        img = Image.open(img_path)\n",
        "        img_t = standard_transforms(img)\n",
        "        batch_t = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "        # Esegui la predizione\n",
        "        with torch.no_grad():\n",
        "            output = alexnet(batch_t)\n",
        "\n",
        "        predicted_probability = output.item()\n",
        "\n",
        "        if predicted_probability > 0.5:\n",
        "            pred = \"Non demented\"\n",
        "            count_non_demented += 1\n",
        "        else:\n",
        "            pred = \"Demented\"\n",
        "            count_demented += 1\n",
        "\n",
        "        # Salva la predizione\n",
        "        predictions.append((img_file, pred))\n",
        "\n",
        "# Stampa i risultati\n",
        "print(f\"Numero di immagini classificate come 'Demented': {count_demented}\")\n",
        "print(f\"Numero di immagini classificate come 'Non demented': {count_non_demented}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}